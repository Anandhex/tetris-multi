behaviors:
  TetrisAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 128          # Reduced from 256 for GPU memory
      buffer_size: 10240       # Reduced from 100000 for GPU memory
      learning_rate: 0.0003
      beta: 0.01
      epsilon: 0.3
      lambd: 0.98
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: false         # CRITICAL: Set to false to fix GPU tensor mismatch
      hidden_units: 256        # Reduced from 512 for GPU memory
      num_layers: 3            # Reduced from 4 for GPU memory
      vis_encode_type: simple
      memory: null
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:
        gamma: 0.99
        strength: 0.2          # Reduced from 0.3 to save GPU memory
        encoding_size: 128     # Reduced from 256 for GPU memory
        learning_rate: 0.001
    behavioral_cloning: null
    framework: pytorch
    keep_checkpoints: 5
    max_steps: 10000000
    time_horizon: 256          # Reduced from 512 for GPU memory
    summary_freq: 10000
    threaded: true

# Add global torch settings for GPU
torch_settings:
  device: cuda





# behaviors:
#   TetrisAgent:
#     trainer_type: ppo
#     hyperparameters:
#       batch_size: 256
#       buffer_size: 100000
#       learning_rate: 0.0003
#       beta: 0.01
#       epsilon: 0.3
#       lambd: 0.98
#       num_epoch: 3
#       learning_rate_schedule: linear
#     network_settings:
#       normalize: true
#       hidden_units: 512
#       num_layers: 4
#       vis_encode_type: simple
#       memory: null
#     reward_signals:
#       extrinsic:
#         gamma: 0.99
#         strength: 1.0
#       curiosity:
#         gamma: 0.99
#         strength: 0.3
#         encoding_size: 256
#         learning_rate: 0.001
#     behavioral_cloning: null
#     framework: pytorch
#     keep_checkpoints: 5
#     max_steps: 10000000
#     time_horizon: 512
#     summary_freq: 10000
#     threaded: true
