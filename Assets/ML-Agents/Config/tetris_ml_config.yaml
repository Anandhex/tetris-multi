behaviors:
  TetrisAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 1024 # Increased for better stability
      buffer_size: 10240 # More reasonable size
      learning_rate: 3.0e-4 # Higher learning rate for faster convergence
      beta: 0.01 # Increased for better exploration
      epsilon: 0.2 # Standard PPO value
      lambd: 0.95 # Good balance
      num_epoch: 3 # Reduced to prevent overfitting
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 256 # Reduced for faster training
      num_layers: 3 # Reduced complexity
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:
        gamma: 0.99
        encoding_size: 128 # Reduced for efficiency
        strength: 0.02 # Added strength parameter
        learning_rate: 1.0e-3
    max_steps: 2000000 # Increased for better learning
    time_horizon: 128 # Reduced for faster episodes
    summary_freq: 5000 # More frequent summaries
    checkpoint_interval: 50000 # Regular checkpoints
    keep_checkpoints: 10
    threaded: true

environment_parameters:
  # Fixed curriculum with proper thresholds
  tetromino_types:
    curriculum:
      - name: "basic_i_piece"
        value: 1
        completion_criteria:
          min_lesson_length: 1000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 50.0 # Positive threshold
      - name: "i_and_o_pieces"
        value: 2
        completion_criteria:
          min_lesson_length: 1500
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 100.0
      - name: "basic_three"
        value: 3
        completion_criteria:
          min_lesson_length: 2000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 200.0
      - name: "most_pieces"
        value: 5
        completion_criteria:
          min_lesson_length: 3000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 400.0
      - name: "all_pieces"
        value: 7
        completion_criteria:
          min_lesson_length: 5000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 800.0

  board_height:
    curriculum:
      - name: "basic_i_piece"
        value: 6
        completion_criteria:
          min_lesson_length: 1000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 50.0
      - name: "i_and_o_pieces"
        value: 8
        completion_criteria:
          min_lesson_length: 1500
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 100.0
      - name: "basic_three"
        value: 12
        completion_criteria:
          min_lesson_length: 2000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 200.0
      - name: "most_pieces"
        value: 16
        completion_criteria:
          min_lesson_length: 3000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 400.0
      - name: "all_pieces"
        value: 20
        completion_criteria:
          min_lesson_length: 5000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 800.0

  board_preset:
    curriculum:
      - name: "basic_i_piece"
        value: 1 # minimal_pre_config
        completion_criteria:
          min_lesson_length: 1000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 50.0
      - name: "i_and_o_pieces"
        value: 2 # basic_placement
        completion_criteria:
          min_lesson_length: 1500
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 100.0
      - name: "basic_three"
        value: 3 # guided_stacking
        completion_criteria:
          min_lesson_length: 2000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 200.0
      - name: "most_pieces"
        value: 4 # structured_challenge
        completion_criteria:
          min_lesson_length: 3000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 400.0
      - name: "all_pieces"
        value: 0 # empty_board (full game)
        completion_criteria:
          min_lesson_length: 5000
          measure: reward
          behavior: "TetrisAgent"
          signal_smoothing: true
          threshold: 800.0

  # Fixed reward parameters (removed from curriculum)
  comboMultiplier: 0.8
  tetrisClearRewardMultiplier: 20.0
  tripleLineClearRewardMultiplier: 10.0
  doubleLineClearRewardMultiplier: 5.0
  perfectClearBonus: 100.0
  tSpinReward: 2.0
  iPieceGapFillBonus: 1.5
  deathPenalty: 5.0

  # Reduced penalties for better learning
  stagnationPenaltyFactor: 0.0001
  stackHeightPenalty: 0.01
  holeCreationPenalty: 0.5 # Much lower than your 0.99979
  uselessRotationPenalty: 0.005
  idleActionPenalty: 0.0005

  # Balanced rewards
  roughnessRewardMultiplier: 0.5
  roughnessPenaltyMultiplier: 0.005
  holeFillReward: 2.0
  wellRewardMultiplier: 0.3
  iPieceInWellBonus: 1.0
  maxWellRewardCap: 2.0
  accessibilityRewardMultiplier: 0.3
  accessibilityPenaltyMultiplier: 0.02

  # New parameters for better learning
  moveDownActionReward: 0.01
  hardDropActionReward: 0.05
  partialRowFillRewardMultiplier: 0.02
  horizontalStackingRewardMultiplier: 1.0
